{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a613998",
   "metadata": {
    "id": "3a613998"
   },
   "source": [
    "\n",
    "# Modelo por Segmento (Plato) — XGBoost\n",
    "**Fecha:** 2025-11-01 23:17:09\n",
    "\n",
    "Este notebook entrena **un modelo por plato** para mejorar la precisión (accuracy) aprovechando patrones específicos de cada segmento.\n",
    "\n",
    "**Estructura:**\n",
    "1. Imports y Configuración  \n",
    "2. Carga robusta del dataset + Detección flexible de columnas  \n",
    "3. Preparación de features y generación opcional de lags/rollings  \n",
    "4. **Tuning por Segmento** con `RandomizedSearchCV` (compatibilidad sin early-stopping en CV)  \n",
    "5. **Reentrenamiento Final por Segmento** con early-stopping vía `xgboost.train`  \n",
    "6. Métricas por segmento + Métrica global (promedio ponderado)  \n",
    "7. Próximos pasos sugeridos según resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "SpOgDtBUtIam",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpOgDtBUtIam",
    "outputId": "00590d29-4ccd-4af3-b83e-4a148ab6a716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Imports y Configuración\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print(\"xgboost version:\", xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ea0b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "a0ea0b34",
    "outputId": "27028dc6-d216-440b-dc71-da5b54580c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH encontrado: ..\\..\\data\\processed\\dataset_forecast_diario.csv\n",
      "Detectado:\n",
      " - Fecha      : fecha\n",
      " - Target     : cantidad\n",
      " - Segmento   : plato\n",
      " - Calendario : {'feriado': 'feriado', 'fin_de_semana': 'fin_de_semana', 'dow': 'dow', 'mes': 'mes'}\n",
      " - Series     : ['lag_1', 'lag_7', 'lag_14', 'lag_28', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_28', 'rolling_std_28']\n",
      "Shape: (21530, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>plato</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>monto_total</th>\n",
       "      <th>anio</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>dow</th>\n",
       "      <th>fin_de_semana</th>\n",
       "      <th>feriado</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_std_7</th>\n",
       "      <th>rolling_mean_14</th>\n",
       "      <th>rolling_std_14</th>\n",
       "      <th>rolling_mean_28</th>\n",
       "      <th>rolling_std_28</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>mes_sin</th>\n",
       "      <th>mes_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>19.642857</td>\n",
       "      <td>5.415180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>2.819997</td>\n",
       "      <td>11.928571</td>\n",
       "      <td>2.894671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>2.070197</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>2.737609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha  plato  cantidad  monto_total  anio  mes  dia  dow  \\\n",
       "0 2021-01-15      1      13.0        338.0  2021    1   15    4   \n",
       "1 2021-01-15      5      21.0        525.0  2021    1   15    4   \n",
       "2 2021-01-15      6      11.0        264.0  2021    1   15    4   \n",
       "\n",
       "   fin_de_semana  feriado  ...  rolling_mean_7  rolling_std_7  \\\n",
       "0              0        0  ...       19.000000       4.123106   \n",
       "1              0        0  ...       12.571429       2.819997   \n",
       "2              0        0  ...        9.571429       2.070197   \n",
       "\n",
       "   rolling_mean_14  rolling_std_14  rolling_mean_28  rolling_std_28   dow_sin  \\\n",
       "0        19.642857        5.415180              NaN             NaN -0.433884   \n",
       "1        11.928571        2.894671              NaN             NaN -0.433884   \n",
       "2        10.428571        2.737609              NaN             NaN -0.433884   \n",
       "\n",
       "    dow_cos  mes_sin  mes_cos  \n",
       "0 -0.900969      0.0      1.0  \n",
       "1 -0.900969      0.0      1.0  \n",
       "2 -0.900969      0.0      1.0  \n",
       "\n",
       "[3 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2) Carga robusta del dataset + Detección flexible de columnas\n",
    "\n",
    "# Ajusta esta ruta si tu CSV está en otra ubicación.\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"../../data/processed/dataset_forecast_diario.csv\"),\n",
    "    Path(\"/content/-1INF46-Plan_Compras_Produccion/data/processed/dataset_forecast_diario.csv\"),\n",
    "    Path(\"/workspace/-1INF46-Plan_Compras_Produccion/data/processed/dataset_forecast_diario.csv\"),\n",
    "]\n",
    "\n",
    "DATA_PATH = None\n",
    "for p in CANDIDATE_PATHS:\n",
    "    if p.exists():\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "\n",
    "print(\"DATA_PATH encontrado:\", DATA_PATH)\n",
    "\n",
    "assert DATA_PATH is not None, \"No se encontró el dataset. Ajusta CANDIDATE_PATHS o define DATA_PATH manualmente.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "DATE_COL_CANDS = [\"fecha\", \"ds\", \"date\", \"FECHA\"]\n",
    "TARGET_CANDS    = [\"cantidad\", \"ventas\", \"ventas_total\", \"venta_total\", \"y\", \"target\", \"ventas_real\"]\n",
    "PLATO_CANDS     = [\"plato\", \"plato_id\", \"id_plato\", \"producto\", \"categoria\"]\n",
    "\n",
    "CALENDAR_CANDS = {\n",
    "    \"feriado\":        [\"feriado\",\"is_holiday\",\"es_feriado\"],\n",
    "    \"fin_de_semana\":  [\"fin_de_semana\",\"is_weekend\"],\n",
    "    \"dow\":            [\"dia_semana\",\"dow\"],\n",
    "    \"mes\":            [\"mes\",\"month\"],\n",
    "}\n",
    "\n",
    "SERIES_CANDS = [\n",
    "    \"lag_1\",\"lag_7\",\"lag_14\",\"lag_21\",\"lag_28\",\n",
    "    \"rolling_mean_7\",\"rolling_std_7\",\"rolling_mean_14\",\"rolling_std_14\",\"rolling_mean_28\",\"rolling_std_28\"\n",
    "]\n",
    "\n",
    "def pick_col(cands, cols_lower):\n",
    "    for c in cands:\n",
    "        if c in cols_lower:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# normaliza nombres para búsqueda (lower)\n",
    "cols_lower = [c.lower() for c in df.columns]\n",
    "colmap = {c.lower(): c for c in df.columns}\n",
    "\n",
    "date_col   = pick_col(DATE_COL_CANDS, cols_lower)\n",
    "target_col = pick_col(TARGET_CANDS, cols_lower)\n",
    "plato_col  = pick_col(PLATO_CANDS, cols_lower)\n",
    "\n",
    "assert date_col is not None, f\"No se detectó columna de fecha. Candidatas: {DATE_COL_CANDS}\"\n",
    "assert target_col is not None, f\"No se detectó target (ventas). Candidatas: {TARGET_CANDS}\"\n",
    "assert plato_col is not None, f\"No se detectó columna de 'plato' o categoría. Candidatas: {PLATO_CANDS}\"\n",
    "\n",
    "# mapea a nombres originales (case original)\n",
    "DATE_COL   = colmap[date_col]\n",
    "TARGET_COL = colmap[target_col]\n",
    "PLATO_COL  = colmap[plato_col]\n",
    "\n",
    "calendar_cols = {}\n",
    "for k, cands in CALENDAR_CANDS.items():\n",
    "    sel = pick_col(cands, cols_lower)\n",
    "    if sel is not None:\n",
    "        calendar_cols[k] = colmap[sel]\n",
    "\n",
    "series_cols = [colmap[c] for c in SERIES_CANDS if c in cols_lower]\n",
    "\n",
    "print(\"Detectado:\")\n",
    "print(\" - Fecha      :\", DATE_COL)\n",
    "print(\" - Target     :\", TARGET_COL)\n",
    "print(\" - Segmento   :\", PLATO_COL)\n",
    "print(\" - Calendario :\", calendar_cols)\n",
    "print(\" - Series     :\", series_cols)\n",
    "\n",
    "# parse de fecha y orden\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "df = df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# Por si hay valores nulos en target, eliminarlos\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0hvwLi8DUizY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0hvwLi8DUizY",
    "outputId": "727ac678-0067-48f4-dccd-32479ac1e38a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_invierno</th>\n",
       "      <th>temp_otono</th>\n",
       "      <th>temp_primavera</th>\n",
       "      <th>temp_verano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp_invierno  temp_otono  temp_primavera  temp_verano\n",
       "0          False       False           False         True\n",
       "1          False       False           False         True\n",
       "2          False       False           False         True\n",
       "3          False       False           False         True\n",
       "4          False       False           False         True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(regex=\"temp\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b58659",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8b58659",
    "outputId": "0c1bc9e3-a23e-4189-9248-5f09fd10d368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset modelable: (21362, 46)\n",
      "Top segmentos por cantidad de filas:\n",
      "plato\n",
      "1     1798\n",
      "2     1798\n",
      "3     1798\n",
      "4     1798\n",
      "5     1798\n",
      "6     1798\n",
      "7     1798\n",
      "8     1798\n",
      "9     1796\n",
      "10    1763\n",
      "Name: cantidad, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Preparación de features (lags/rollings si faltan)\n",
    "NEED_LAGS = any(c not in df.columns for c in [\"lag_7\", \"rolling_mean_7\", \"rolling_std_7\"])\n",
    "\n",
    "def add_lags_rollings(g, target, lags=[1,7,14,21,28], wins=[7,14,28]):\n",
    "    g = g.sort_values(DATE_COL).copy()\n",
    "    for L in lags:\n",
    "        g[f\"lag_{L}\"] = g[target].shift(L)\n",
    "    for W in wins:\n",
    "        g[f\"rolling_mean_{W}\"] = g[target].shift(1).rolling(W, min_periods=max(2, W//2)).mean()\n",
    "        g[f\"rolling_std_{W}\"]  = g[target].shift(1).rolling(W, min_periods=max(2, W//2)).std()\n",
    "    return g\n",
    "\n",
    "if NEED_LAGS:\n",
    "    print(\"Generando lags/rollings por segmento…\")\n",
    "    df = df.groupby(PLATO_COL, group_keys=False).apply(lambda g: add_lags_rollings(g, TARGET_COL))\n",
    "\n",
    "# Definición de features\n",
    "regressors = []\n",
    "regressors += list(calendar_cols.values())\n",
    "regressors += [c for c in series_cols if c in df.columns]\n",
    "\n",
    "# Limpieza mínima\n",
    "for c in regressors:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df_model = df.dropna(subset=regressors + [TARGET_COL]).copy()\n",
    "print(\"Dataset modelable:\", df_model.shape)\n",
    "\n",
    "seg_counts = df_model.groupby(PLATO_COL)[TARGET_COL].size().sort_values(ascending=False)\n",
    "print(\"Top segmentos por cantidad de filas:\")\n",
    "print(seg_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "YPBY8Rr2YsCz",
   "metadata": {
    "id": "YPBY8Rr2YsCz"
   },
   "outputs": [],
   "source": [
    "# 4) Utilidades de métrica\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    # Calculate RMSE manually as squared=False might not be supported in older sklearn versions\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-6, None))) * 100\n",
    "    smape= 100*np.mean(2*np.abs(y_true-y_pred)/(np.abs(y_true)+np.abs(y_pred)+1e-6))\n",
    "    return {\"MAE\":mae,\"RMSE\":rmse,\"R2\":r2,\"MAPE\":mape,\"sMAPE\":smape,\"Accuracy(1-MAPE)\":100-mape}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b6c52",
   "metadata": {
    "id": "a90b6c52"
   },
   "source": [
    "# Task\n",
    "To create a time series forecasting model using LSTM, prepare the data by transforming it into sequential samples of `(timesteps, features)` and normalizing the features. Then, define a basic LSTM model architecture with TensorFlow/Keras and iterate through each data segment to train a specific LSTM model for each, storing the trained models. Finally, generate predictions, recalculate evaluation metrics (MAE, RMSE, MAPE, sMAPE, Accuracy) for the LSTM model both per segment and globally, and compare these results with previous Random Forest and XGBoost models to assess performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b02bf",
   "metadata": {
    "id": "a46b02bf"
   },
   "source": [
    "## Preparar Datos para LSTM\n",
    "\n",
    "### Subtask:\n",
    "Transformar los datos de series de tiempo en un formato secuencial ((samples, timesteps, features)) apto para LSTM y normalizar las características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450956b2",
   "metadata": {
    "id": "450956b2"
   },
   "source": [
    "**Reasoning**:\n",
    "First, I will define the number of timesteps for the LSTM and the features that will be used as input for the model. This is the initial setup required before transforming the data into a sequential format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54c3d7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e54c3d7c",
    "outputId": "c4842b74-b62c-4638-c034-a80a5a1c51ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps for LSTM: 7\n",
      "LSTM Features: ['feriado', 'fin_de_semana', 'dow', 'mes', 'lag_7', 'lag_14', 'lag_28', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_28', 'rolling_std_28', 'cantidad']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Define the number of timesteps\n",
    "TIMESTEPS = 7 # This can be adjusted\n",
    "\n",
    "# 2. Define the features for the LSTM model\n",
    "# This includes regressors and the target itself as part of the input sequence\n",
    "# We exclude 'lag_1' because the target at the previous step will be implicitly available through the sequence\n",
    "lstm_features = [c for c in regressors if c != 'lag_1']\n",
    "# Ensure TARGET_COL is in the features to be scaled and used in the sequence\n",
    "if TARGET_COL not in lstm_features:\n",
    "    lstm_features.append(TARGET_COL)\n",
    "\n",
    "print(f\"Timesteps for LSTM: {TIMESTEPS}\")\n",
    "print(f\"LSTM Features: {lstm_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec90992",
   "metadata": {
    "id": "8ec90992"
   },
   "source": [
    "**Reasoning**:\n",
    "Now, I will create a function `create_lstm_sequences` to transform the data for a given segment into sequential samples suitable for an LSTM model, including feature scaling and sequence generation. Then, I will apply this function to each segment in the `df_model` to generate `X` and `y` for each `plato`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91bb9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b91bb9a7",
    "outputId": "592b16e2-1c82-46ba-94a3-521cee2f5070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LSTM sequences for each segment...\n",
      "Generated sequences for 12 segments.\n",
      "Example for segment 1:\n",
      "  X shape: (1791, 7, 14)\n",
      "  y shape: (1791,)\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_sequences(df_segment, timesteps, features, target_col):\n",
    "    # Sort by date to ensure correct sequence order\n",
    "    df_segment = df_segment.sort_values(DATE_COL).copy()\n",
    "\n",
    "    # Scale features. Fit scaler on this segment's data.\n",
    "    # Handle potential NaN values before scaling by filling them, e.g., with 0 or mean/median.\n",
    "    # For simplicity, we'll drop rows with NaNs in features for now, but a more robust approach might impute.\n",
    "    df_segment_clean = df_segment[features + [DATE_COL]].dropna(subset=features)\n",
    "\n",
    "    if df_segment_clean.empty or len(df_segment_clean) <= timesteps:\n",
    "        return np.array([]), np.array([]), None # Not enough data for sequences\n",
    "\n",
    "    data_to_scale = df_segment_clean[features].values\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(timesteps, len(scaled_data)):\n",
    "        X.append(scaled_data[i-timesteps:i])\n",
    "        y.append(df_segment_clean[target_col].iloc[i]) # Target is the actual value for the next timestep\n",
    "\n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "# Prepare to store sequences and scalers for each segment\n",
    "segment_data = {}\n",
    "segment_scalers = {}\n",
    "\n",
    "# Group by PLATO_COL and apply the function\n",
    "print(\"Generating LSTM sequences for each segment...\")\n",
    "for plato_id, group in df_model.groupby(PLATO_COL):\n",
    "    X_segment, y_segment, scaler_segment = create_lstm_sequences(group, TIMESTEPS, lstm_features, TARGET_COL)\n",
    "    if X_segment.size > 0:\n",
    "        segment_data[plato_id] = {'X': X_segment, 'y': y_segment}\n",
    "        segment_scalers[plato_id] = scaler_segment\n",
    "\n",
    "print(f\"Generated sequences for {len(segment_data)} segments.\")\n",
    "\n",
    "# Display shape of first segment's data as an example\n",
    "if segment_data:\n",
    "    first_plato = next(iter(segment_data))\n",
    "    print(f\"Example for segment {first_plato}:\")\n",
    "    print(f\"  X shape: {segment_data[first_plato]['X'].shape}\")\n",
    "    print(f\"  y shape: {segment_data[first_plato]['y'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afdaace",
   "metadata": {
    "id": "4afdaace"
   },
   "source": [
    "## Definir Arquitectura del Modelo LSTM\n",
    "\n",
    "### Subtask:\n",
    "Definir una arquitectura básica de red neuronal LSTM utilizando TensorFlow/Keras para la regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486f11a",
   "metadata": {
    "id": "f486f11a"
   },
   "source": [
    "**Reasoning**:\n",
    "I will import the necessary TensorFlow/Keras modules and define a function to build a basic LSTM model as instructed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fa95a2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fa95a2a",
    "outputId": "8f95566d-09ef-4520-99dc-b2f385ac2294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "LSTM model building function defined.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "def build_lstm_model(timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(timesteps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "print(\"LSTM model building function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cb4d9",
   "metadata": {
    "id": "fd9cb4d9"
   },
   "source": [
    "## Entrenar Modelo LSTM por Segmento\n",
    "\n",
    "### Subtask:\n",
    "Iterar a través de cada segmento de datos, entrenar un modelo LSTM específico para cada uno con los datos preparados y almacenar los modelos entrenados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd0d0d",
   "metadata": {
    "id": "ffbd0d0d"
   },
   "source": [
    "**Reasoning**:\n",
    "I will now iterate through each segment's data, build and train an LSTM model for each, and store the trained models in a dictionary called `lstm_models` as per the instructions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1ddca9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1ddca9a",
    "outputId": "54f787bd-e30c-4f6b-a265-9030eef60f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM models for each segment...\n",
      "\n",
      "Training LSTM for segment 1 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 1 trained and stored.\n",
      "\n",
      "Training LSTM for segment 2 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 2 trained and stored.\n",
      "\n",
      "Training LSTM for segment 3 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 3 trained and stored.\n",
      "\n",
      "Training LSTM for segment 4 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 4 trained and stored.\n",
      "\n",
      "Training LSTM for segment 5 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 5 trained and stored.\n",
      "\n",
      "Training LSTM for segment 6 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 6 trained and stored.\n",
      "\n",
      "Training LSTM for segment 7 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 7 trained and stored.\n",
      "\n",
      "Training LSTM for segment 8 (X shape: (1791, 7, 14), y shape: (1791,))...\n",
      "LSTM model for segment 8 trained and stored.\n",
      "\n",
      "Training LSTM for segment 9 (X shape: (1789, 7, 14), y shape: (1789,))...\n",
      "LSTM model for segment 9 trained and stored.\n",
      "\n",
      "Training LSTM for segment 10 (X shape: (1756, 7, 14), y shape: (1756,))...\n",
      "LSTM model for segment 10 trained and stored.\n",
      "\n",
      "Training LSTM for segment 11 (X shape: (1753, 7, 14), y shape: (1753,))...\n",
      "LSTM model for segment 11 trained and stored.\n",
      "\n",
      "Training LSTM for segment 12 (X shape: (1652, 7, 14), y shape: (1652,))...\n",
      "LSTM model for segment 12 trained and stored.\n",
      "Finished training 12 LSTM models.\n"
     ]
    }
   ],
   "source": [
    "lstm_models = {}\n",
    "\n",
    "print(\"Training LSTM models for each segment...\")\n",
    "for plato_id, data in segment_data.items():\n",
    "    X_segment = data['X']\n",
    "    y_segment = data['y']\n",
    "\n",
    "    # Ensure enough data points for training after sequence creation\n",
    "    if X_segment.shape[0] == 0 or len(y_segment) == 0:\n",
    "        print(f\"Skipping segment {plato_id} due to insufficient data for training.\")\n",
    "        continue\n",
    "\n",
    "    timesteps = X_segment.shape[1]\n",
    "    n_features = X_segment.shape[2]\n",
    "\n",
    "    model = build_lstm_model(timesteps, n_features)\n",
    "\n",
    "    print(f\"\\nTraining LSTM for segment {plato_id} (X shape: {X_segment.shape}, y shape: {y_segment.shape})...\")\n",
    "    # Train the model\n",
    "    # Using verbose=0 to suppress output for each epoch, set to 1 or 2 for more detail\n",
    "    model.fit(X_segment, y_segment, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    lstm_models[plato_id] = model\n",
    "    print(f\"LSTM model for segment {plato_id} trained and stored.\")\n",
    "\n",
    "print(f\"Finished training {len(lstm_models)} LSTM models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0a605",
   "metadata": {
    "id": "8fc0a605"
   },
   "source": [
    "## Generar Predicciones LSTM\n",
    "\n",
    "### Subtask:\n",
    "Utilizar los modelos LSTM entrenados para generar predicciones sobre el conjunto de datos de entrenamiento/validación para cada segmento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8331b2c",
   "metadata": {
    "id": "d8331b2c"
   },
   "source": [
    "**Reasoning**:\n",
    "I will now generate predictions for each segment using the trained LSTM models and store both the predictions and the actual values in separate dictionaries as instructed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9229825a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9229825a",
    "outputId": "25b85e73-3b95-406a-f993-9948195e5d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LSTM predictions for each segment...\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 1.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 2.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 3.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 4.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 5.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 6.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 7.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 8.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 9.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 10.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Predictions generated for segment 11.\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions generated for segment 12.\n",
      "Finished generating predictions for 12 segments.\n",
      "Example for segment 1:\n",
      "  Predictions shape: (1791,)\n",
      "  Actuals shape: (1791,)\n"
     ]
    }
   ],
   "source": [
    "lstm_predictions = {}\n",
    "lstm_actuals = {}\n",
    "\n",
    "print(\"Generating LSTM predictions for each segment...\")\n",
    "for plato_id, data in segment_data.items():\n",
    "    X_segment = data['X']\n",
    "    y_segment = data['y']\n",
    "\n",
    "    # Retrieve the trained model for this segment\n",
    "    if plato_id in lstm_models:\n",
    "        model = lstm_models[plato_id]\n",
    "\n",
    "        # Generate predictions\n",
    "        # Keras predict returns a 2D array, so flatten it\n",
    "        predictions = model.predict(X_segment).flatten()\n",
    "\n",
    "        # Store predictions and actuals\n",
    "        lstm_predictions[plato_id] = predictions\n",
    "        lstm_actuals[plato_id] = y_segment\n",
    "        print(f\"Predictions generated for segment {plato_id}.\")\n",
    "    else:\n",
    "        print(f\"No LSTM model found for segment {plato_id}. Skipping predictions.\")\n",
    "\n",
    "print(f\"Finished generating predictions for {len(lstm_predictions)} segments.\")\n",
    "\n",
    "# Display shape of first segment's predictions and actuals as an example\n",
    "if lstm_predictions:\n",
    "    first_plato = next(iter(lstm_predictions))\n",
    "    print(f\"Example for segment {first_plato}:\")\n",
    "    print(f\"  Predictions shape: {lstm_predictions[first_plato].shape}\")\n",
    "    print(f\"  Actuals shape: {lstm_actuals[first_plato].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c89a01",
   "metadata": {
    "id": "51c89a01"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous step successfully generated predictions for each segment. The next logical step, as per the main task, is to calculate evaluation metrics for these predictions, both per segment and globally. I will reuse the `eval_metrics` function defined earlier to achieve this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84e69fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b84e69fb",
    "outputId": "4fe3979e-71a5-46a8-84ca-13379397dedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating LSTM evaluation metrics per segment...\n",
      "Segment 1 LSTM Metrics: {'MAE': 3.323392215752189, 'RMSE': np.float64(4.195486942028651), 'R2': 0.3264642222520916, 'MAPE': np.float64(16.89362048463072), 'sMAPE': np.float64(15.436319572376146), 'Accuracy(1-MAPE)': np.float64(83.10637951536928)}\n",
      "Segment 2 LSTM Metrics: {'MAE': 3.169757165701146, 'RMSE': np.float64(4.035969217174082), 'R2': 0.3676212296435787, 'MAPE': np.float64(16.369130123413917), 'sMAPE': np.float64(15.870214890012226), 'Accuracy(1-MAPE)': np.float64(83.63086987658608)}\n",
      "Segment 3 LSTM Metrics: {'MAE': 2.5705366991938723, 'RMSE': np.float64(3.258964845211859), 'R2': 0.4955858123985084, 'MAPE': np.float64(20.307703334182918), 'sMAPE': np.float64(18.42718706546975), 'Accuracy(1-MAPE)': np.float64(79.69229666581708)}\n",
      "Segment 4 LSTM Metrics: {'MAE': 3.024525132810251, 'RMSE': np.float64(3.7468406435894877), 'R2': 0.3383122356587206, 'MAPE': np.float64(19.30349577013711), 'sMAPE': np.float64(17.495597017675514), 'Accuracy(1-MAPE)': np.float64(80.69650422986288)}\n",
      "Segment 5 LSTM Metrics: {'MAE': 2.469236684604306, 'RMSE': np.float64(3.1082100019250425), 'R2': 0.4160737763542621, 'MAPE': np.float64(20.576936389101384), 'sMAPE': np.float64(18.795796116069337), 'Accuracy(1-MAPE)': np.float64(79.42306361089862)}\n",
      "Segment 6 LSTM Metrics: {'MAE': 2.356295850808097, 'RMSE': np.float64(2.9444093078260547), 'R2': 0.41849197323458154, 'MAPE': np.float64(21.491113430392854), 'sMAPE': np.float64(19.753217902076752), 'Accuracy(1-MAPE)': np.float64(78.50888656960714)}\n",
      "Segment 7 LSTM Metrics: {'MAE': 1.9228011990711718, 'RMSE': np.float64(2.419185859424253), 'R2': 0.460016719451528, 'MAPE': np.float64(24.238710209850463), 'sMAPE': np.float64(20.816049562099412), 'Accuracy(1-MAPE)': np.float64(75.76128979014953)}\n",
      "Segment 8 LSTM Metrics: {'MAE': 1.8377036137796527, 'RMSE': np.float64(2.302874889616548), 'R2': 0.432733422096102, 'MAPE': np.float64(28.927084169216826), 'sMAPE': np.float64(23.677666514384608), 'Accuracy(1-MAPE)': np.float64(71.07291583078317)}\n",
      "Segment 9 LSTM Metrics: {'MAE': 1.6053014415945668, 'RMSE': np.float64(2.0353285891974204), 'R2': 0.4458525383030293, 'MAPE': np.float64(30.916793418581285), 'sMAPE': np.float64(25.303351498337033), 'Accuracy(1-MAPE)': np.float64(69.08320658141872)}\n",
      "Segment 10 LSTM Metrics: {'MAE': 1.1231005576042488, 'RMSE': np.float64(1.4228664280453456), 'R2': 0.5048213030723121, 'MAPE': np.float64(41.014856203015206), 'sMAPE': np.float64(30.938786439075127), 'Accuracy(1-MAPE)': np.float64(58.985143796984794)}\n",
      "Segment 11 LSTM Metrics: {'MAE': 1.0175760594083456, 'RMSE': np.float64(1.2768318574346393), 'R2': 0.5736210546675333, 'MAPE': np.float64(38.34447577966427), 'sMAPE': np.float64(28.689689240468663), 'Accuracy(1-MAPE)': np.float64(61.65552422033573)}\n",
      "Segment 12 LSTM Metrics: {'MAE': 0.9668751775352488, 'RMSE': np.float64(1.1976110861529812), 'R2': 0.46256263764072514, 'MAPE': np.float64(46.911940086871674), 'sMAPE': np.float64(35.901579477651666), 'Accuracy(1-MAPE)': np.float64(53.088059913128326)}\n",
      "\n",
      "Calculating Global LSTM evaluation metrics...\n",
      "Global LSTM Metrics: {'MAE': 2.1267373182460076, 'RMSE': np.float64(2.8585394631144156), 'R2': 0.8428689209203045, 'MAPE': np.float64(26.9353172703294), 'sMAPE': np.float64(22.480302588010915), 'Accuracy(1-MAPE)': np.float64(73.06468272967061)}\n",
      "Finished calculating metrics.\n"
     ]
    }
   ],
   "source": [
    "lstm_segment_metrics = {}\n",
    "all_lstm_predictions = np.array([])\n",
    "all_lstm_actuals = np.array([])\n",
    "\n",
    "print(\"Calculating LSTM evaluation metrics per segment...\")\n",
    "for plato_id in lstm_predictions.keys():\n",
    "    y_true = lstm_actuals[plato_id]\n",
    "    y_pred = lstm_predictions[plato_id]\n",
    "\n",
    "    metrics = eval_metrics(y_true, y_pred)\n",
    "    lstm_segment_metrics[plato_id] = metrics\n",
    "    print(f\"Segment {plato_id} LSTM Metrics: {metrics}\")\n",
    "\n",
    "    all_lstm_predictions = np.append(all_lstm_predictions, y_pred)\n",
    "    all_lstm_actuals = np.append(all_lstm_actuals, y_true)\n",
    "\n",
    "print(\"\\nCalculating Global LSTM evaluation metrics...\")\n",
    "global_lstm_metrics = eval_metrics(all_lstm_actuals, all_lstm_predictions)\n",
    "print(f\"Global LSTM Metrics: {global_lstm_metrics}\")\n",
    "\n",
    "print(\"Finished calculating metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801dc87",
   "metadata": {
    "id": "3801dc87"
   },
   "source": [
    "## Comparativa Final de Modelos\n",
    "\n",
    "Aquí presentamos una tabla comparativa de las métricas globales obtenidas por el modelo Random Forest, el modelo híbrido (Random Forest + XGBoost en segmentos de baja precisión), y el modelo LSTM. Esto nos permitirá evaluar el rendimiento relativo de cada enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2caa04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "6d2caa04",
    "outputId": "638ff467-a35d-42b4-bda6-cc8b21dd0cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparativa de Métricas Globales ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest (Inicial)</th>\n",
       "      <th>RF + XGBoost (Híbrido)</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.41</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.03</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>32.66</td>\n",
       "      <td>27.63</td>\n",
       "      <td>26.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMAPE</th>\n",
       "      <td>26.01</td>\n",
       "      <td>22.81</td>\n",
       "      <td>22.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy(1-MAPE)</th>\n",
       "      <td>67.34</td>\n",
       "      <td>72.37</td>\n",
       "      <td>73.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Random Forest (Inicial)  RF + XGBoost (Híbrido)   LSTM\n",
       "MAE                                  2.41                    2.24   2.13\n",
       "RMSE                                 3.03                    2.82   2.86\n",
       "MAPE                                32.66                   27.63  26.94\n",
       "sMAPE                               26.01                   22.81  22.48\n",
       "Accuracy(1-MAPE)                    67.34                   72.37  73.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Recolectar métricas globales de cada modelo\n",
    "# Las métricas para el RF inicial fueron: weighted_mae, weighted_rmse, weighted_mape, weighted_smape\n",
    "# Las métricas para el RF+XGBoost combinado fueron: weighted_mae, weighted_rmse, weighted_mape, weighted_smape (con nuevas features)\n",
    "# Las métricas para LSTM fueron: global_lstm_metrics\n",
    "\n",
    "# Asegurémonos de tener los valores correctos de los estados anteriores, asumiendo que se guardaron en variables con nombres similares\n",
    "\n",
    "# Globales RF iniciales (se obtuvieron de la celda de metrics_rf_df original)\n",
    "# Para ser precisos, buscaremos los valores de la ejecucion original de metrics_rf_df\n",
    "# Si no estan disponibles, usaremos los valores del ultimo summary que los contenga\n",
    "\n",
    "# Recuperar los valores del ultimo summary que contiene las metricas globales ponderadas de RF inicial\n",
    "# 'MAE : 2.41', 'RMSE: 3.03', 'MAPE: 32.66%', 'sMAPE: 26.01%', 'Accuracy(1-MAPE): 67.34%'\n",
    "\n",
    "rf_initial_metrics = {\n",
    "    'MAE': 2.41, 'RMSE': 3.03, 'MAPE': 32.66, 'sMAPE': 26.01, 'Accuracy(1-MAPE)': 67.34\n",
    "}\n",
    "\n",
    "# Recuperar los valores del ultimo summary que contiene las metricas globales ponderadas de RF+XGBoost (con calendar features)\n",
    "# 'MAE : 2.24', 'RMSE: 2.82', 'MAPE: 27.63%', 'sMAPE: 22.81%', 'Accuracy(1-MAPE): 72.37%'\n",
    "\n",
    "rf_xgb_hybrid_metrics = {\n",
    "    'MAE': 2.24, 'RMSE': 2.82, 'MAPE': 27.63, 'sMAPE': 22.81, 'Accuracy(1-MAPE)': 72.37\n",
    "}\n",
    "\n",
    "# Métricas globales LSTM (ya están en 'global_lstm_metrics')\n",
    "lstm_metrics = {\n",
    "    'MAE': global_lstm_metrics['MAE'],\n",
    "    'RMSE': global_lstm_metrics['RMSE'],\n",
    "    'MAPE': global_lstm_metrics['MAPE'],\n",
    "    'sMAPE': global_lstm_metrics['sMAPE'],\n",
    "    'Accuracy(1-MAPE)': global_lstm_metrics['Accuracy(1-MAPE)']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Random Forest (Inicial)': rf_initial_metrics,\n",
    "    'RF + XGBoost (Híbrido)': rf_xgb_hybrid_metrics,\n",
    "    'LSTM': lstm_metrics\n",
    "})\n",
    "\n",
    "print(\"--- Comparativa de Métricas Globales ---\")\n",
    "display(comparison_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7778d925",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "7778d925",
    "outputId": "82a23df8-8449-4a2e-a382-751d46eac3ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Métricas del Modelo LSTM por Segmento ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Accuracy(1-MAPE)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.323392</td>\n",
       "      <td>4.195487</td>\n",
       "      <td>0.326464</td>\n",
       "      <td>16.893620</td>\n",
       "      <td>15.436320</td>\n",
       "      <td>83.106380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.169757</td>\n",
       "      <td>4.035969</td>\n",
       "      <td>0.367621</td>\n",
       "      <td>16.369130</td>\n",
       "      <td>15.870215</td>\n",
       "      <td>83.630870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.570537</td>\n",
       "      <td>3.258965</td>\n",
       "      <td>0.495586</td>\n",
       "      <td>20.307703</td>\n",
       "      <td>18.427187</td>\n",
       "      <td>79.692297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.024525</td>\n",
       "      <td>3.746841</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>19.303496</td>\n",
       "      <td>17.495597</td>\n",
       "      <td>80.696504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.469237</td>\n",
       "      <td>3.108210</td>\n",
       "      <td>0.416074</td>\n",
       "      <td>20.576936</td>\n",
       "      <td>18.795796</td>\n",
       "      <td>79.423064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.356296</td>\n",
       "      <td>2.944409</td>\n",
       "      <td>0.418492</td>\n",
       "      <td>21.491113</td>\n",
       "      <td>19.753218</td>\n",
       "      <td>78.508887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.922801</td>\n",
       "      <td>2.419186</td>\n",
       "      <td>0.460017</td>\n",
       "      <td>24.238710</td>\n",
       "      <td>20.816050</td>\n",
       "      <td>75.761290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.837704</td>\n",
       "      <td>2.302875</td>\n",
       "      <td>0.432733</td>\n",
       "      <td>28.927084</td>\n",
       "      <td>23.677667</td>\n",
       "      <td>71.072916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.605301</td>\n",
       "      <td>2.035329</td>\n",
       "      <td>0.445853</td>\n",
       "      <td>30.916793</td>\n",
       "      <td>25.303351</td>\n",
       "      <td>69.083207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.123101</td>\n",
       "      <td>1.422866</td>\n",
       "      <td>0.504821</td>\n",
       "      <td>41.014856</td>\n",
       "      <td>30.938786</td>\n",
       "      <td>58.985144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.017576</td>\n",
       "      <td>1.276832</td>\n",
       "      <td>0.573621</td>\n",
       "      <td>38.344476</td>\n",
       "      <td>28.689689</td>\n",
       "      <td>61.655524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.966875</td>\n",
       "      <td>1.197611</td>\n",
       "      <td>0.462563</td>\n",
       "      <td>46.911940</td>\n",
       "      <td>35.901579</td>\n",
       "      <td>53.088060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE      RMSE        R2       MAPE      sMAPE  Accuracy(1-MAPE)\n",
       "plato                                                                      \n",
       "1      3.323392  4.195487  0.326464  16.893620  15.436320         83.106380\n",
       "2      3.169757  4.035969  0.367621  16.369130  15.870215         83.630870\n",
       "3      2.570537  3.258965  0.495586  20.307703  18.427187         79.692297\n",
       "4      3.024525  3.746841  0.338312  19.303496  17.495597         80.696504\n",
       "5      2.469237  3.108210  0.416074  20.576936  18.795796         79.423064\n",
       "6      2.356296  2.944409  0.418492  21.491113  19.753218         78.508887\n",
       "7      1.922801  2.419186  0.460017  24.238710  20.816050         75.761290\n",
       "8      1.837704  2.302875  0.432733  28.927084  23.677667         71.072916\n",
       "9      1.605301  2.035329  0.445853  30.916793  25.303351         69.083207\n",
       "10     1.123101  1.422866  0.504821  41.014856  30.938786         58.985144\n",
       "11     1.017576  1.276832  0.573621  38.344476  28.689689         61.655524\n",
       "12     0.966875  1.197611  0.462563  46.911940  35.901579         53.088060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertir el diccionario de métricas por segmento a un DataFrame\n",
    "lstm_segment_metrics_df = pd.DataFrame.from_dict(lstm_segment_metrics, orient='index')\n",
    "lstm_segment_metrics_df.index.name = PLATO_COL\n",
    "\n",
    "print(\"--- Métricas del Modelo LSTM por Segmento ---\")\n",
    "display(lstm_segment_metrics_df)\n",
    "\n",
    "# Save metrics to CSV\n",
    "output_dir = Path(\"../../reports/metrics\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "lstm_segment_metrics_df.to_csv(output_dir / \"lstm_metrics.csv\")\n",
    "print(f\"Metrics saved to {output_dir / 'lstm_metrics.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c28903e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "c28903e0",
    "outputId": "4f043168-9fac-4a8e-925f-6b21ed1de242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Métricas Globales del Modelo LSTM ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Accuracy(1-MAPE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Valor</th>\n",
       "      <td>2.126737</td>\n",
       "      <td>2.858539</td>\n",
       "      <td>0.842869</td>\n",
       "      <td>26.935317</td>\n",
       "      <td>22.480303</td>\n",
       "      <td>73.064683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE      RMSE        R2       MAPE      sMAPE  Accuracy(1-MAPE)\n",
       "Valor  2.126737  2.858539  0.842869  26.935317  22.480303         73.064683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertir el diccionario de métricas globales a un DataFrame\n",
    "lstm_global_metrics_df = pd.DataFrame.from_dict(global_lstm_metrics, orient='index', columns=['Valor'])\n",
    "\n",
    "print(\"\\n--- Métricas Globales del Modelo LSTM ---\")\n",
    "display(lstm_global_metrics_df.T) # Transponer para una mejor visualización de una sola fila"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4ec22",
   "metadata": {
    "id": "6ee4ec22"
   },
   "source": [
    "## Comparar Resultados LSTM\n",
    "\n",
    "### Subtask:\n",
    "Analizar y comparar el rendimiento del modelo LSTM con los resultados obtenidos previamente con la combinación de Random Forest y XGBoost, para determinar si LSTM ofrece una mejora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04716185",
   "metadata": {
    "id": "04716185"
   },
   "source": [
    "### Comparación de Rendimiento de Modelos\n",
    "\n",
    "Para realizar una comparación exhaustiva entre el modelo LSTM y los modelos previos de Random Forest y XGBoost, es necesario tener acceso a las métricas de evaluación (MAE, RMSE, MAPE, sMAPE, R2, Accuracy) obtenidas de esos modelos.\n",
    "\n",
    "**Dado que esas métricas no están disponibles en el estado actual del kernel, por favor, refiérase a sus salidas o registros anteriores de los modelos de Random Forest y XGBoost para obtener los siguientes datos:**\n",
    "\n",
    "*   **Métricas Globales (Random Forest y XGBoost):** MAE, RMSE, R2, MAPE, sMAPE, Accuracy\n",
    "*   **Métricas por Segmento (Random Forest y XGBoost):** Un diccionario o tabla que contenga estas mismas métricas para cada `plato_id`.\n",
    "\n",
    "Una vez que tenga estos datos, podrá comparar directamente con las métricas LSTM que se muestran a continuación. Busque:\n",
    "\n",
    "*   **Menores valores** para MAE, RMSE, MAPE, sMAPE.\n",
    "*   **Mayores valores** para R2 y Accuracy.\n",
    "\n",
    "Esto le permitirá determinar si el modelo LSTM ofrece una mejora significativa, un rendimiento similar o inferior en comparación con los modelos anteriores, tanto a nivel global como para segmentos específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2e9e6",
   "metadata": {
    "id": "7bd2e9e6"
   },
   "source": [
    "**Reasoning**:\n",
    "Now that the instructions for manual comparison are provided, I will display the global and per-segment LSTM metrics to the user so they can perform the comparison with their previously obtained Random Forest and XGBoost metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d83dd8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d83dd8f",
    "outputId": "876977da-5269-474a-98fd-ade45f341047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LSTM Global Metrics ---\n",
      "  MAE: 2.1267\n",
      "  RMSE: 2.8585\n",
      "  R2: 0.8429\n",
      "  MAPE: 26.9353\n",
      "  sMAPE: 22.4803\n",
      "  Accuracy(1-MAPE): 73.0647\n",
      "\n",
      "--- LSTM Metrics Per Segment ---\n",
      "\n",
      "Segment 1:\n",
      "  MAE: 3.3234\n",
      "  RMSE: 4.1955\n",
      "  R2: 0.3265\n",
      "  MAPE: 16.8936\n",
      "  sMAPE: 15.4363\n",
      "  Accuracy(1-MAPE): 83.1064\n",
      "\n",
      "Segment 2:\n",
      "  MAE: 3.1698\n",
      "  RMSE: 4.0360\n",
      "  R2: 0.3676\n",
      "  MAPE: 16.3691\n",
      "  sMAPE: 15.8702\n",
      "  Accuracy(1-MAPE): 83.6309\n",
      "\n",
      "Segment 3:\n",
      "  MAE: 2.5705\n",
      "  RMSE: 3.2590\n",
      "  R2: 0.4956\n",
      "  MAPE: 20.3077\n",
      "  sMAPE: 18.4272\n",
      "  Accuracy(1-MAPE): 79.6923\n",
      "\n",
      "Segment 4:\n",
      "  MAE: 3.0245\n",
      "  RMSE: 3.7468\n",
      "  R2: 0.3383\n",
      "  MAPE: 19.3035\n",
      "  sMAPE: 17.4956\n",
      "  Accuracy(1-MAPE): 80.6965\n",
      "\n",
      "Segment 5:\n",
      "  MAE: 2.4692\n",
      "  RMSE: 3.1082\n",
      "  R2: 0.4161\n",
      "  MAPE: 20.5769\n",
      "  sMAPE: 18.7958\n",
      "  Accuracy(1-MAPE): 79.4231\n",
      "\n",
      "Segment 6:\n",
      "  MAE: 2.3563\n",
      "  RMSE: 2.9444\n",
      "  R2: 0.4185\n",
      "  MAPE: 21.4911\n",
      "  sMAPE: 19.7532\n",
      "  Accuracy(1-MAPE): 78.5089\n",
      "\n",
      "Segment 7:\n",
      "  MAE: 1.9228\n",
      "  RMSE: 2.4192\n",
      "  R2: 0.4600\n",
      "  MAPE: 24.2387\n",
      "  sMAPE: 20.8160\n",
      "  Accuracy(1-MAPE): 75.7613\n",
      "\n",
      "Segment 8:\n",
      "  MAE: 1.8377\n",
      "  RMSE: 2.3029\n",
      "  R2: 0.4327\n",
      "  MAPE: 28.9271\n",
      "  sMAPE: 23.6777\n",
      "  Accuracy(1-MAPE): 71.0729\n",
      "\n",
      "Segment 9:\n",
      "  MAE: 1.6053\n",
      "  RMSE: 2.0353\n",
      "  R2: 0.4459\n",
      "  MAPE: 30.9168\n",
      "  sMAPE: 25.3034\n",
      "  Accuracy(1-MAPE): 69.0832\n",
      "\n",
      "Segment 10:\n",
      "  MAE: 1.1231\n",
      "  RMSE: 1.4229\n",
      "  R2: 0.5048\n",
      "  MAPE: 41.0149\n",
      "  sMAPE: 30.9388\n",
      "  Accuracy(1-MAPE): 58.9851\n",
      "\n",
      "Segment 11:\n",
      "  MAE: 1.0176\n",
      "  RMSE: 1.2768\n",
      "  R2: 0.5736\n",
      "  MAPE: 38.3445\n",
      "  sMAPE: 28.6897\n",
      "  Accuracy(1-MAPE): 61.6555\n",
      "\n",
      "Segment 12:\n",
      "  MAE: 0.9669\n",
      "  RMSE: 1.1976\n",
      "  R2: 0.4626\n",
      "  MAPE: 46.9119\n",
      "  sMAPE: 35.9016\n",
      "  Accuracy(1-MAPE): 53.0881\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- LSTM Global Metrics ---\")\n",
    "for metric, value in global_lstm_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n--- LSTM Metrics Per Segment ---\")\n",
    "for plato_id, metrics in lstm_segment_metrics.items():\n",
    "    print(f\"\\nSegment {plato_id}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4a0e7",
   "metadata": {
    "id": "dca4a0e7"
   },
   "source": [
    "## Final Task\n",
    "\n",
    "### Subtask:\n",
    "Revisar el rendimiento del modelo LSTM y decidir los próximos pasos, como el ajuste de hiperparámetros o la integración en un ensamble.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef339e",
   "metadata": {
    "id": "d8ef339e"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Q&A\n",
    "\n",
    "The task aimed to assess the LSTM model's performance and determine next steps. Due to the unavailability of previous Random Forest and XGBoost model metrics within the current execution environment, a direct, automated comparison could not be performed. Therefore, a definitive decision on whether LSTM offers an improvement or which next steps (like hyperparameter tuning or ensembling) are most suitable cannot be made solely based on this process. Manual comparison with previously recorded metrics is required to proceed.\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   **Data Preparation for LSTM**: Time series data was successfully transformed into a sequential format, with `TIMESTEPS` set to 7 and 14 features (`['feriado', 'fin_de_semana', 'dow', 'mes', 'lag_7', 'lag_14', 'lag_28', 'rolling_mean_7', 'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_28', 'rolling_std_28', 'cantidad']`) prepared for LSTM input. Each of the 12 data segments was scaled independently using `StandardScaler`, resulting in input sequences of shape `(samples, 7, 14)` and target values of shape `(samples,)`.\n",
    "*   **LSTM Model Architecture**: A basic TensorFlow/Keras `Sequential` model was defined, consisting of one `LSTM` layer with 50 units and 'relu' activation, followed by a `Dense` output layer with a single unit. The model was compiled using the 'adam' optimizer and 'mse' loss function.\n",
    "*   **Per-Segment Model Training**: A dedicated LSTM model was trained for each of the 12 segments using their respective prepared data, with `epochs=50` and `batch_size=32`. All trained models were successfully stored.\n",
    "*   **LSTM Prediction and Evaluation**:\n",
    "    *   Predictions were generated for all segments.\n",
    "    *   **Global LSTM Performance**: The aggregated performance across all segments yielded a Mean Absolute Error (MAE) of 2.1278, Root Mean Squared Error (RMSE) of 2.8634, R-squared (R2) of 0.8423, Mean Absolute Percentage Error (MAPE) of 27.3834%, symmetric Mean Absolute Percentage Error (sMAPE) of 22.5163%, and an Accuracy (1-MAPE) of 72.6166%.\n",
    "    *   **Per-Segment LSTM Performance**: Evaluation metrics varied considerably across segments. R2 values ranged from 0.3028 (Segment 4) to 0.5463 (Segment 12). MAE values ranged from 0.8943 (Segment 12) to 3.1635 (Segment 2). MAPE values showed a wide range, from 15.0017% (Segment 1) to 47.1893% (Segment 12).\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   **Manual Comparison Required**: To determine the best model, a direct comparison of the global and per-segment LSTM metrics (MAE, RMSE, R2, MAPE, sMAPE, Accuracy) with the previously obtained metrics from the Random Forest and XGBoost models is crucial.\n",
    "*   **Hyperparameter Tuning**: Given the varying performance across segments and the base architecture used, further optimization of the LSTM models through hyperparameter tuning (e.g., number of LSTM units, layers, epochs, batch size, learning rate, and different optimizers) could potentially improve forecasting accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35e708",
   "metadata": {},
   "source": [
    "# Exportar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6946272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio para modelos LSTM creado en: ..\\..\\models\\LSTM_Models\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "lstm_output_dir = Path(\"../../models/LSTM_Models\")\n",
    "lstm_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio para modelos LSTM creado en: {lstm_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79189d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportando modelos LSTM por segmento...\n",
      "  Modelo LSTM para plato 1 guardado en ..\\..\\models\\LSTM_Models\\plato_1.keras\n",
      "  Modelo LSTM para plato 2 guardado en ..\\..\\models\\LSTM_Models\\plato_2.keras\n",
      "  Modelo LSTM para plato 3 guardado en ..\\..\\models\\LSTM_Models\\plato_3.keras\n",
      "  Modelo LSTM para plato 4 guardado en ..\\..\\models\\LSTM_Models\\plato_4.keras\n",
      "  Modelo LSTM para plato 5 guardado en ..\\..\\models\\LSTM_Models\\plato_5.keras\n",
      "  Modelo LSTM para plato 6 guardado en ..\\..\\models\\LSTM_Models\\plato_6.keras\n",
      "  Modelo LSTM para plato 7 guardado en ..\\..\\models\\LSTM_Models\\plato_7.keras\n",
      "  Modelo LSTM para plato 8 guardado en ..\\..\\models\\LSTM_Models\\plato_8.keras\n",
      "  Modelo LSTM para plato 9 guardado en ..\\..\\models\\LSTM_Models\\plato_9.keras\n",
      "  Modelo LSTM para plato 10 guardado en ..\\..\\models\\LSTM_Models\\plato_10.keras\n",
      "  Modelo LSTM para plato 11 guardado en ..\\..\\models\\LSTM_Models\\plato_11.keras\n",
      "  Modelo LSTM para plato 12 guardado en ..\\..\\models\\LSTM_Models\\plato_12.keras\n",
      "Exportación de todos los modelos LSTM completada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Exportando modelos LSTM por segmento...\")\n",
    "\n",
    "for plato_id, model in lstm_models.items():\n",
    "    # Keras models can be saved directly. We'll use the SavedModel format.\n",
    "    model_path = lstm_output_dir / f\"plato_{plato_id}.keras\"\n",
    "    model.save(model_path)\n",
    "    print(f\"  Modelo LSTM para plato {plato_id} guardado en {model_path}\")\n",
    "\n",
    "print(\"Exportación de todos los modelos LSTM completada.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
